
=== Evaluation (GOOD/WEAK/CONFUSED) classifier report ===
              precision    recall  f1-score   support

    CONFUSED      0.968     0.882     0.923        34
        GOOD      0.926     1.000     0.962       113
        WEAK      0.956     0.843     0.896        51

    accuracy                          0.939       198
   macro avg      0.950     0.908     0.927       198
weighted avg      0.941     0.939     0.938       198

Confusion matrix (rows=true, cols=pred):
[[ 30   2   2]
 [  0 113   0]
 [  1   7  43]]

=== Evaluation classifier – TEST set ===
              precision    recall  f1-score   support

    CONFUSED      0.892     0.971     0.930        34
        GOOD      0.917     0.973     0.944       113
        WEAK      0.902     0.725     0.804        51

    accuracy                          0.909       198
   macro avg      0.904     0.890     0.893       198
weighted avg      0.909     0.909     0.906       198


=== Tone (analytical/curious/frustrated/neutral/playful) classifier report ===
              precision    recall  f1-score   support

  analytical      0.930     0.964     0.946        55
     curious      0.800     0.857     0.828        28
  frustrated      0.912     0.738     0.816        42
     neutral      0.750     0.825     0.786        40
     playful      0.879     0.879     0.879        33

    accuracy                          0.859       198
   macro avg      0.854     0.853     0.851       198
weighted avg      0.863     0.859     0.858       198

Confusion matrix (rows=true, cols=pred):
[[53  1  0  1  0]
 [ 0 24  0  2  2]
 [ 0  3 31  7  1]
 [ 3  1  2 33  1]
 [ 1  1  1  1 29]]

=== Tone classifier – TEST set ===
              precision    recall  f1-score   support

  analytical      0.963     0.897     0.929        58
     curious      0.862     0.862     0.862        29
  frustrated      0.806     0.853     0.829        34
     neutral      0.791     0.850     0.819        40
     playful      0.944     0.919     0.932        37

    accuracy                          0.879       198
   macro avg      0.873     0.876     0.874       198
weighted avg      0.883     0.879     0.880       198
